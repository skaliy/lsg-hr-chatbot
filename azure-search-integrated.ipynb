{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook is inspired by Microsofts notebook found on Github: [Vector search in Python (Azure AI Search)](https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/readme.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Azure AI Search parameters\n",
    "\n",
    "search_service_name = os.environ[\"AZURE_SEARCH_SERVICE\"]\n",
    "search_endpoint = f\"https://{search_service_name}.search.windows.net\"\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_KEY\"])\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "\n",
    "# Azure Blob Storage parameters\n",
    "blob_connection_string = os.environ[\"BLOB_CONNECTION_STRING\"]\n",
    "blob_container_name = os.environ[\"BLOB_CONTAINER_NAME\"]\n",
    "\n",
    "# Azure OpenAI parameters\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "azure_openai_embedding_name = os.environ[\"AZURE_OPENAI_EMBEDDING_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Blob Storage  \n",
    "Retrieve documents from Blob Storage. You can use the sample documents in the [documents](../data/documents) folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient  \n",
    "# Connect to Blob Storage using connection string\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Running a few tests to verify blob connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection by listing all containers in blob storage\n",
    "all_containers = blob_service_client.list_containers(include_metadata=True)\n",
    "for container in all_containers:\n",
    "    print(container['name'], container['metadata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect your Blob storage to a data source in Azure AI Search\n",
    "Makes data from a blob storage available as a data source to an indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (SearchIndexerDataContainer, SearchIndexerDataSourceConnection)\n",
    "from azure.search.documents.indexes._generated.models import NativeBlobSoftDeleteDeletionDetectionPolicy\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint, credential=credential)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=SearchIndexerDataContainer(name=blob_container_name),\n",
    "    data_deletion_detection_policy=NativeBlobSoftDeleteDeletionDetectionPolicy()\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index\n",
    "Index is used to store data and make it searchable with Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    # Standard fields\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=False, filterable=False, facetable=False, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SimpleField(name=\"storage_path\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),  \n",
    "    SimpleField(name=\"storage_content_type\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),  \n",
    "    SimpleField(name=\"storage_last_modified\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),  \n",
    "    # Vector field for embeddings\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    # Add custom metadatafields here\n",
    "    SearchField(name=\"Orgname\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),    \n",
    "    SearchField(name=\"Genorgindex\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),\n",
    "    SearchField(name=\"Name\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),\n",
    "    SimpleField(name=\"Statusname\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),    \n",
    "    SimpleField(name=\"Validfromdate\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Docmoduletype\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Docid\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Approver_middlename\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Accesslevelid\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Approver_lastname\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Doctype\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Doctypeid\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Approver_firstname\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Docstatusid\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Validity_custmizeddomainname\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Validity_customizeddomain_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "    SimpleField(name=\"Validity_customizeddomain_genindex\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False, searchable=False),\n",
    "]  \n",
    "\n",
    "# Configure the vector search configuration (standard config here from the Microsoft example). \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            parameters=HnswParameters(  \n",
    "                m=4,  \n",
    "                ef_construction=400,  \n",
    "                ef_search=500,  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "        ExhaustiveKnnAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_name,  \n",
    "                api_key=azure_openai_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a skillset\n",
    "Skillsets is used to process and enhance files before being indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerIndexProjections,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "\n",
    "# Splitt skill to chunk documents  \n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=2000, # Standard config from Microsoft example. \n",
    "    page_overlap_length=500,  # Standard config from Microsoft example.\n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=azure_openai_endpoint,  \n",
    "    deployment_id=azure_openai_embedding_name,  \n",
    "    api_key=azure_openai_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "    ],  \n",
    ")  \n",
    "\n",
    "index_projections = SearchIndexerIndexProjections(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[\n",
    "                # Map fields to the index  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),  \n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "                InputFieldMappingEntry(name=\"storage_path\", source=\"/document/metadata_storage_path\"),  \n",
    "                InputFieldMappingEntry(name=\"storage_content_type\", source=\"/document/metadata_storage_content_type\"),  \n",
    "                InputFieldMappingEntry(name=\"storage_last_modified\", source=\"/document/metadata_storage_last_modified\"),  \n",
    "                # Add custom metadata fields here\n",
    "                InputFieldMappingEntry(name=\"Orgname\", source=\"/document/Orgname\"), \n",
    "                InputFieldMappingEntry(name=\"Statusname\", source=\"/document/Statusname\"), \n",
    "                InputFieldMappingEntry(name=\"Validfromdate\", source=\"/document/Validfromdate\"),\n",
    "                InputFieldMappingEntry(name=\"Genorgindex\", source=\"/document/Genorgindex\"), \n",
    "                InputFieldMappingEntry(name=\"Name\", source=\"/document/Name\"), \n",
    "                InputFieldMappingEntry(name=\"Docmoduletype\", source=\"/document/Docmoduletype\"), \n",
    "                InputFieldMappingEntry(name=\"Docid\", source=\"/document/Docid\"), \n",
    "                InputFieldMappingEntry(name=\"Approver_middlename\", source=\"/document/Approver_middlename\"), \n",
    "                InputFieldMappingEntry(name=\"Accesslevelid\", source=\"/document/Accesslevelid\"), \n",
    "                InputFieldMappingEntry(name=\"Approver_lastname\", source=\"/document/Approver_lastname\"), \n",
    "                InputFieldMappingEntry(name=\"Doctype\", source=\"/document/Doctype\"), \n",
    "                InputFieldMappingEntry(name=\"Doctypeid\", source=\"/document/Doctypeid\"), \n",
    "                InputFieldMappingEntry(name=\"Approver_firstname\", source=\"/document/Approver_firstname\"), \n",
    "                InputFieldMappingEntry(name=\"Docstatusid\", source=\"/document/Docstatusid\"),\n",
    "                InputFieldMappingEntry(name=\"Validity_custmizeddomainname\", source=\"/document/Validity_custmizeddomainname\"), \n",
    "                InputFieldMappingEntry(name=\"Validity_customizeddomain_id\", source=\"/document/Validity_customizeddomain_id\"), \n",
    "                InputFieldMappingEntry(name=\"Validity_customizeddomain_genindex\", source=\"/document/Validity_customizeddomain_genindex\")\n",
    "\n",
    "\n",
    "                \n",
    "            ],  \n",
    "        ),  \n",
    "    ], \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=[split_skill, embedding_skill],  \n",
    "    index_projections=index_projections,  \n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(endpoint, credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping,\n",
    "    IndexingSchedule\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")],\n",
    "    # Schedule the indexer to run every hour\n",
    "    schedule=IndexingSchedule(interval=\"PT1H\", start_time=datetime.utcnow().isoformat() + \"Z\")\n",
    ")\n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "\n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# Indexers scheduling \n",
    "\n",
    "#Terraform \n",
    "# Enable soft delete for blobs and containers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
